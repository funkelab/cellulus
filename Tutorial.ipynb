{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cellulus Tutorial: Segmenting 2D Data\n",
    "In this tutorial we're going to walk through segmenting a 2D cell dataset, assuming very little experience with python. Example code and data will be provided. Feel free to skip any steps that do not apply to your own set-up.\n",
    "\n",
    "This tutorial will assume that you have python and conda installed. If this is not the case, visit https://www.anaconda.com/ to get set up, then return to this tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a virtual environment to work in\n",
    "We're going to create a conda environment to run cellulus in. The following line scan be executed in ananconda prompt to create and activate a cellulus environment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create -n cellulus python\n",
    "conda activate cellulus\n",
    "conda install pytorch torchvision pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "git clone https://github.com/funkelab/cellulus.git\n",
    "cd cellulus\n",
    "pip install -e .\n",
    "pip install git+https://github.com/funkelab/funlib.learn.torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, you'll also benefit from having numpy and matplotlib installed. They are not essential for Cellulus to run, but help us to view the outputs. Since this is a new environment we're working with, we can isntall them by running the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install numpy, matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the pre-requisites installed, we can start using Cellulus. Cellulus expects your data to be stored in Zarr container (more on that here https://zarr.readthedocs.io/en/stable/). If your data is not in a zarr format, it needs to be converted. Experienced users could create a dataloader for your own format if preferred."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, w're going to create the configuration files that tell Cellulus hwo to run right here, in the code. Alternatively, this can be done by creating/editing a train.toml file. These are two methods for sharing the same information with Cellulus. \n",
    "\n",
    "First, we have to import the configuration classes from the Cellulus library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.configs.experiment_config import ExperimentConfig\n",
    "from cellulus.configs.model_config import ModelConfig\n",
    "from cellulus.configs.train_config import TrainConfig\n",
    "from cellulus.configs.inference_config import InferenceConfig\n",
    "from cellulus.configs.dataset_config import DatasetConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these config classes stores information relevant to a different step in the segmentation process, to give users more control over the end result. Let's create some DatasetConfigs to tell cellulus where to find the zarr files contining the images we want to segement.\n",
    "\n",
    "We're going to divide our data into a training and validation set. This is commonly done in machine elarning, to ensure that the models we train are applicable to data that isn't in our training dataset, such as data we acquire in the future. If this isn't applicable to you, e.g. you already have all of the data you want to segment, then your train, validation and test configs can all point to the same dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_config = {'container_path':'[PATH TO YOUR ZARR]',\n",
    "                                     'dataset_name':'[raw image]'}\n",
    "\n",
    "validate_dataset_config = {'container_path':'[PATH TO YOUR ZARR]',\n",
    "                                     'dataset_name':'raw'}\n",
    "\n",
    "inference_dataset_config = {'container_path':'[PATH TO YOUR ZARR]',\n",
    "                                     'dataset_name':'raw'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our ModelConfig and TrainConfig. These objects define the structure of the UNet we'll be training, and how we'd like to train it, respectively. The TrainConfig requires the dataset configs we defined earlier. \n",
    "The UNet we'll be defining is based on the funlib_torch library. If we already had a pre-trained model, we could supply a checkpoint to taht model, but for now we'll just provide the number of featuremaps and the factor by which to increase the number of feature maps between levels of the U-Net. \n",
    "\n",
    "We'll provide some values to define number of iterations we want to train for, and how often the model and snapshots should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config =  {'num_fmaps':256,\n",
    "                     'fmap_inc_factor':3,\n",
    "                     'downsampling_factors':[(3,3)]}\n",
    "\n",
    "train_config = {'batch_size':8,\n",
    "                    'save_snapshot_every':200,\n",
    "                    'save_model_every':200,\n",
    "                    'train_data_config':train_dataset_config,\n",
    "                    'validate_data_config':validate_dataset_config,\n",
    "                    'max_iterations':1000}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define an experiment config. This contains our ModelConfig and TrainConfig, and helps us to ecapsulate all those previouss ettings into a single object, so that the results can be grouped together easily. All we need to do is give the experiment we're running here a name, and an approximate size for the objects we want to segment, given in world units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config = ExperimentConfig(experiment_name=\"Tutorial Experiment\",\n",
    "                                   object_size=10.0,\n",
    "                                   model_config=model_config,\n",
    "                                   train_config=train_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all of the information required to run our experiemnt. If you've chosen to define these values in a .toml file instead of in the code, then this next step can be executed from the command line. If you've defined your configs following the steps above, we'll start the training loop from here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.train import train\n",
    "\n",
    "train(experiment_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the train function has finished executing, we should have a few new files and folders in our directory. Loss.png gives us a quick glace at the loss curve for our model, approximating how much the model we've trained has improved at creating Object Centric Embeddings. Snapshots.zarr shows us a trained embedding at a few, regular intervals in the training loop. Finally, models stores the trained models, which we can use to segment new images. \n",
    "\n",
    "Since we have some data in the lung dataset that the model has never seen (lung.zarr/train), let's see how well our newly trained model performs at segmenting it. \n",
    "\n",
    "To do that, we need to define another configuration object, this time an InferenceConfig. The InferenceConfig will contain the paths to the data we want to segment, as well as where we'd like the outputs of each step of the segmentation process saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output_config = {'container_path':'[PATH TO ZARR OUTPUT]',\n",
    "                      'dataset_name':'prediction'}\n",
    "\n",
    "seg_output_config = {'container_path':'[PATH TO ZARR OUTPUT]',\n",
    "                      'dataset_name':'segmentation'}\n",
    "\n",
    "postproc_output_config = {'container_path':'[PATH TO ZARR OUTPUT]',\n",
    "                      'dataset_name':'post_process'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have access to a dataset of ground truth labels for the data you'd like to segment, that can be provided here as well as an evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dataset_config = {'container_path':'[PATH TO GROUNDTRUTH LABELS]',\n",
    "                             'dataset_name':'labels'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inf_config = InferenceConfig(dataset_config=inference_dataset_config,\n",
    "                                  prediction_dataset_config=pred_output_config,\n",
    "                                  segmentation_dataset_config=seg_output_config,\n",
    "                                  post_processed_dataset_config=postproc_output_config,\n",
    "                                  evaluation_dataset_config=evaluation_dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.models import get_model\n",
    "from cellulus.datasets import get_dataset\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions and segmentations, we need to load the model that was produced during training. Thankfully, the best performing model (according to the validation dataset) has been saved in the file `best_loss.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = experiment_config.train_config\n",
    "model_config = experiment_config.model_config\n",
    "\n",
    "train_dataset = get_dataset(\n",
    "        dataset_config=train_config.train_data_config,\n",
    "        crop_size=train_config.crop_size,\n",
    "        control_point_spacing=train_config.control_point_spacing,\n",
    "        control_point_jitter=train_config.control_point_jitter,\n",
    "    )\n",
    "\n",
    "model_example = get_model(\n",
    "        in_channels=train_dataset.get_num_channels(),\n",
    "        out_channels=train_dataset.get_num_spatial_dims(),\n",
    "        num_fmaps=model_config.num_fmaps,\n",
    "        fmap_inc_factor=model_config.fmap_inc_factor,\n",
    "        features_in_last_layer=model_config.features_in_last_layer,\n",
    "        downsampling_factors=model_config.downsampling_factors,\n",
    "        num_spatial_dims=train_dataset.get_num_spatial_dims(),\n",
    "    )\n",
    "\n",
    "model_example = model_example.cuda()\n",
    "\n",
    "path_to_model = \".models\\\\best_loss.pth\"\n",
    "\n",
    "model_example.load_state_dict(torch.load(path_to_model)['model_state_dict'])\n",
    "\n",
    "model_example.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a good quality model loaded, we can segment our dataset! Producing segmentations is done over three steps, handled by three functions. First we run predict, providing our model and the inference config as arguments. This function will create object-centric embeddings for the dataset that `InferenceConfig.dataset_config` points to. The resulting OCEs will be saved into a zarr container at `InferenceConfig.prediction_dataset_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.predict import predict\n",
    "predict(model_example,inference_config=test_inf_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our OCEs, we can run `segment()` to cluster those embeddings, to create an instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.segment import segment\n",
    "segment(inference_config=test_inf_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can post-process the instance segmentation using `post_process()`, to clean up the segmentations we've produced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellulus.post_process import post_process\n",
    "post_process(inference_config=test_inf_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellulus-refactor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
